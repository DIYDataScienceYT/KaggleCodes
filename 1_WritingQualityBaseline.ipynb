{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdAKVSaSAiWwWDHlidcgc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIYDataScienceYT/KaggleCodes/blob/main/1_WritingQualityBaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Kaggle Dataset"
      ],
      "metadata": {
        "id": "BA9VAabZ6DGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle --quiet"
      ],
      "metadata": {
        "id": "L-iUvXqd6FYh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "competition_name = \"linking-writing-processes-to-writing-quality\"\n",
        "\n",
        "# https://www.kaggle.com/discussions/general/74235\n",
        "\n",
        "# Mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHlUiDaw6VoV",
        "outputId": "44bf6578-8eae-4b84-8f22-8710243a535f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.kaggle\n",
        "!cp /content/drive/MyDrive/Kaggle/kaggle_json/kaggle.json /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BgkBws5xC6B",
        "outputId": "14ee8763-c1ba-4f36-c7df-3a362a84ff79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle competitions download -c {competition_name}\n",
        "\n",
        "! mkdir kaggle_data\n",
        "! unzip {competition_name + \".zip\"} -d kaggle_data\n",
        "\n",
        "# Unmount your Google Drive\n",
        "drive.flush_and_unmount()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHGm0q2W6zwq",
        "outputId": "70fc4e67-c03c-4a66-bb7d-8824733aa453"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading linking-writing-processes-to-writing-quality.zip to /content\n",
            " 95% 103M/108M [00:00<00:00, 191MB/s] \n",
            "100% 108M/108M [00:00<00:00, 178MB/s]\n",
            "Archive:  linking-writing-processes-to-writing-quality.zip\n",
            "  inflating: kaggle_data/sample_submission.csv  \n",
            "  inflating: kaggle_data/test_logs.csv  \n",
            "  inflating: kaggle_data/train_logs.csv  \n",
            "  inflating: kaggle_data/train_scores.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download requirements"
      ],
      "metadata": {
        "id": "4R9c5YJnxteW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama catboost optuna -q"
      ],
      "metadata": {
        "id": "6waMYCdaxzwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "8HJCgd6YC0Zb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6D7Y9BzCvf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e58d95-328f-4c8a-8e12-64d505015501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU times: user 647 ms, sys: 169 ms, total: 816 ms\n",
            "Wall time: 1.04 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "%%time\n",
        "# General library imports:-\n",
        "# displaying styling elements (HTML, Markdown..)\n",
        "from IPython.display import display_html, clear_output, Markdown;\n",
        "# trigger manual garbage collection cycle\n",
        "from gc import collect;\n",
        "# working with dataframes\n",
        "import pandas as pd;\n",
        "# numerical and mathematical operations\n",
        "import numpy as np;\n",
        "# makes copy\n",
        "from copy import deepcopy;\n",
        "# frequence counter\n",
        "from collections import Counter;\n",
        "# regex - string operations\n",
        "import re;\n",
        "\n",
        "# process and os related imports:-\n",
        "# mechanism for parallelizing the execution of functions\n",
        "import joblib;\n",
        "# os properties - run system commands (ls, cd), get process id, generate file hierarchy tree\n",
        "from os import system, getpid, walk;\n",
        "# interface for retrieving information on running processes and system utilization.\n",
        "from psutil import Process;\n",
        "# C library on Unix-like systems\n",
        "import ctypes;\n",
        "libc = ctypes.CDLL(\"libc.so.6\");\n",
        "\n",
        "# styling\n",
        "# pretty-print: used to print asthetically\n",
        "from pprint import pprint;\n",
        "# Fore: color, Style: italics/bold\n",
        "from colorama import Fore, Style, init;\n",
        "# suppresses the display of warnings\n",
        "from warnings import filterwarnings;\n",
        "filterwarnings('ignore');\n",
        "\n",
        "# visualizations\n",
        "# extensible progress bar\n",
        "from tqdm.autonotebook import tqdm;\n",
        "# data visualization\n",
        "import seaborn as sns;\n",
        "import matplotlib.pyplot as plt;\n",
        "# colormap from a list of colors\n",
        "from matplotlib.colors import ListedColormap as LCM;\n",
        "# command to print all plots within notebook, not new window\n",
        "%matplotlib inline\n",
        "\n",
        "print();\n",
        "collect();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# cross-validation\n",
        "from sklearn.model_selection import (RepeatedStratifiedKFold as RSKF,\n",
        "                                     StratifiedKFold as SKF,\n",
        "                                     KFold,\n",
        "                                     RepeatedKFold as RKF,\n",
        "                                     cross_val_score);\n",
        "# ML Models\n",
        "# logging evaluation results and early stopping during training\n",
        "from lightgbm import log_evaluation, early_stopping, LGBMRegressor as LGBMR;\n",
        "from xgboost import XGBRegressor as XGBR;\n",
        "from catboost import CatBoostRegressor as CBR;\n",
        "from sklearn.ensemble import (HistGradientBoostingRegressor as HGBR,\n",
        "                              RandomForestRegressor as RFR,\n",
        "                              ExtraTreesRegressor as ETR,\n",
        "                              BaggingRegressor as BR\n",
        "                             );\n",
        "from sklearn.neighbors import KNeighborsRegressor as KNNR;\n",
        "from sklearn.metrics import mean_squared_error as mse, make_scorer;\n",
        "\n",
        "from sklearn.pipeline import Pipeline, make_pipeline;\n",
        "from sklearn.impute import SimpleImputer;\n",
        "# applying transformers to columns\n",
        "from sklearn.compose import ColumnTransformer;\n",
        "# FT: apply a custom function\n",
        "from sklearn.preprocessing import (FunctionTransformer as FT,\n",
        "                                   StandardScaler, RobustScaler, MinMaxScaler,MaxAbsScaler,\n",
        "                                  );\n",
        "\n",
        "import optuna;\n",
        "from optuna import Trial, trial, create_study;\n",
        "from optuna.samplers import TPESampler, CmaEsSampler;\n",
        "optuna.logging.set_verbosity = optuna.logging.ERROR;\n",
        "\n",
        "print();\n",
        "collect();"
      ],
      "metadata": {
        "id": "_VQy-Ypc4Pjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a1c250-0085-4fc4-fbf4-c8c358543710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU times: user 1.66 s, sys: 187 ms, total: 1.85 s\n",
            "Wall time: 2.65 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Defining global configurations and functions:-\n",
        "\n",
        "# Setting rc parameters in seaborn for plots and graphs-\n",
        "# Reference - https://matplotlib.org/stable/tutorials/introductory/customizing.html:-\n",
        "# To alter this, refer to matplotlib.rcParams.keys()\n",
        "\n",
        "sns.set({\"axes.facecolor\"       : \"#ffffff\",\n",
        "         \"figure.facecolor\"     : \"#ffffff\",\n",
        "         \"axes.edgecolor\"       : \"#000000\",\n",
        "         \"grid.color\"           : \"#ffffff\",\n",
        "         \"font.family\"          : ['Cambria'],\n",
        "         \"axes.labelcolor\"      : \"#000000\",\n",
        "         \"xtick.color\"          : \"#000000\",\n",
        "         \"ytick.color\"          : \"#000000\",\n",
        "         \"grid.linewidth\"       : 0.75,\n",
        "         \"grid.linestyle\"       : \"--\",\n",
        "         \"axes.titlecolor\"      : '#0099e6',\n",
        "         'axes.titlesize'       : 8.5,\n",
        "         'axes.labelweight'     : \"bold\",\n",
        "         'legend.fontsize'      : 7.0,\n",
        "         'legend.title_fontsize': 7.0,\n",
        "         'font.size'            : 7.5,\n",
        "         'xtick.labelsize'      : 7.5,\n",
        "         'ytick.labelsize'      : 7.5,\n",
        "        });\n",
        "\n",
        "# Color printing\n",
        "def PrintColor(text:str, color = Fore.BLUE, style = Style.BRIGHT):\n",
        "    \"Prints color outputs using colorama using a text F-string\";\n",
        "    print(style + color + text + Style.RESET_ALL);\n",
        "\n",
        "def GetMemUsage():\n",
        "    \"\"\"\n",
        "    This function defines the memory usage across the kernel.\n",
        "    Source-\n",
        "    https://stackoverflow.com/questions/61366458/how-to-find-memory-usage-of-kaggle-notebook\n",
        "    \"\"\";\n",
        "\n",
        "    pid = getpid();\n",
        "    py = Process(pid);\n",
        "    memory_use = py.memory_info()[0] / 2. ** 30;\n",
        "    return f\"RAM memory GB usage = {memory_use :.4}\";\n",
        "\n",
        "# Making sklearn pipeline outputs as dataframe:-\n",
        "from sklearn import set_config;\n",
        "set_config(transform_output = \"pandas\");\n",
        "pd.set_option('display.max_columns', 50);\n",
        "pd.set_option('display.max_rows', 50);\n",
        "\n",
        "print();\n",
        "collect();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGLKm2wi4sn6",
        "outputId": "1c08986e-3300-4cd8-8222-7bee9f151164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CPU times: user 177 ms, sys: 0 ns, total: 177 ms\n",
            "Wall time: 182 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "zLZLP3OZ5oE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Configuration class:-\n",
        "class CFG:\n",
        "    \"\"\"\n",
        "    Configuration class for parameters and CV strategy for tuning and training\n",
        "    Please use caps lock capital letters while filling in parameters\n",
        "    \"\"\";\n",
        "\n",
        "    # Data preparation:-\n",
        "    version_nb         = 1;\n",
        "    test_req           = \"N\";\n",
        "    test_frac          = 0.01;\n",
        "    load_tr_data       = \"Y\";\n",
        "    gpu_switch         = \"OFF\";\n",
        "    state              = 42;\n",
        "    target             = 'score';\n",
        "\n",
        "    path               = f\"/kaggle/input/linking-writing-processes-to-writing-quality/\";\n",
        "    mydf_path          = f\"/kaggle/input/writingqualitymemoryreduction/\";\n",
        "\n",
        "    # Model Training:-\n",
        "    methods            = [\"LGBM1R\", \"LGBM2R\",\"XGBR\", \"CBR\"];\n",
        "    ML                 = \"Y\";\n",
        "    scl_mthd           = \"Robust\";\n",
        "    n_splits           = 5;\n",
        "    n_repeats          = 5;\n",
        "    nbrnd_erly_stp     = 25;\n",
        "    mdlcv_mthd         = 'RSKF';\n",
        "\n",
        "    # Ensemble:-\n",
        "    ensemble_req       = \"Y\";\n",
        "    enscv_mthd         = \"RKF\";\n",
        "    metric_obj         = 'minimize';\n",
        "    ntrials            = 10 if test_req == \"Y\" else 500;\n",
        "    pstprcs_train      = \"N\";\n",
        "    pstprcs_sub        = \"N\";\n",
        "\n",
        "    # Global variables for plotting:-\n",
        "    grid_specs     = {'visible': True, 'which': 'both', 'linestyle': '--',\n",
        "                      'color': 'lightgrey', 'linewidth': 0.75\n",
        "                     };\n",
        "    title_specs    = {'fontsize': 9, 'fontweight': 'bold', 'color': 'tab:blue'};\n",
        "    suptitle_specs = {'fontsize': 13, 'fontweight': 'bold', 'color': 'blue'};\n",
        "\n",
        "print();\n",
        "PrintColor(f\"--> Configuration done!\\n\");\n",
        "collect();\n",
        "\n",
        "PrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1MFO_wv40E4",
        "outputId": "d21f94c1-a8be-4b95-9b8a-e05cc87a7db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[34m--> Configuration done!\n",
            "\u001b[0m\n",
            "\u001b[1m\u001b[31m\n",
            "RAM memory GB usage = 0.2844\u001b[0m\n",
            "CPU times: user 172 ms, sys: 1.4 ms, total: 174 ms\n",
            "Wall time: 249 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Commonly used CV strategies for later usage:-\n",
        "all_cv= {'KF'  : KFold(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state),\n",
        "         'RKF' : RKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n",
        "         'RSKF': RSKF(n_splits= CFG.n_splits, n_repeats = CFG.n_repeats, random_state= CFG.state),\n",
        "         'SKF' : SKF(n_splits= CFG.n_splits, shuffle = True, random_state= CFG.state)\n",
        "        };\n",
        "\n",
        "all_scaler = \\\n",
        "{\"Z\": StandardScaler(), \"Robust\": RobustScaler(),\"MinMax\": MinMaxScaler(),\"MaxAbs\": MaxAbsScaler()};\n",
        "\n",
        "# Defining the competition metric:-\n",
        "def ScoreMetric(ytrue, ypred)-> float:\n",
        "    \"\"\"\n",
        "    This function calculates the metric for the competition.\n",
        "    ytrue- ground truth array\n",
        "    ypred- predictions\n",
        "    returns - metric value (float)\n",
        "    \"\"\";\n",
        "\n",
        "    return mse(ytrue, ypred, squared = False);\n",
        "\n",
        "# Designing a custom scorer to use in cross_val_predict and cross_val_score:-\n",
        "myscorer = make_scorer(ScoreMetric, greater_is_better = False, needs_proba= False,);\n",
        "\n",
        "# Making a post-process function for predictions:-\n",
        "def PostProcessPred(pred, post_process: str):\n",
        "    \"\"\"\n",
        "    This function post-processes the predictions as per user's discretion\n",
        "    \"\"\";\n",
        "\n",
        "    if post_process == \"Y\":\n",
        "        return np.around(pred * 2) / 2 ;\n",
        "    else:\n",
        "        return pred;\n",
        "\n",
        "print();\n",
        "collect();\n",
        "\n",
        "PrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoctaVnV5pm2",
        "outputId": "b0830adf-7140-4d32-e5a4-e086a144415c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[31m\n",
            "RAM memory GB usage = 0.2844\u001b[0m\n",
            "CPU times: user 188 ms, sys: 2.04 ms, total: 190 ms\n",
            "Wall time: 501 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PreProcessors"
      ],
      "metadata": {
        "id": "AHCh0RS-8OKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "class Preprocessor():\n",
        "    \"\"\"\n",
        "    Thanks to Marcus Chan for the class and the features\n",
        "    Source- https://www.kaggle.com/code/mcpenguin/writing-processes-to-quality-baseline\n",
        "    \"\"\";\n",
        "\n",
        "    def __init__(self):\n",
        "        self.seed = CFG.state;\n",
        "\n",
        "        self.activities =\\\n",
        "        ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste'];\n",
        "        self.events = \\\n",
        "        ['q', 'Space', 'Backspace', 'Shift',\n",
        "         'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',',\n",
        "         'ArrowDown', 'ArrowUp', 'Enter',\n",
        "         'CapsLock', \"'\", 'Delete', 'Unidentified'\n",
        "        ];\n",
        "        self.text_changes = \\\n",
        "        ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\",\n",
        "         '\"', '-', '?', ';', '=', '/', '\\\\', ':'\n",
        "        ];\n",
        "        self.punctuations =\\\n",
        "        ['\"', '.', ',', \"'\", '-', ';', ':',\n",
        "         '?', '!', '<', '>', '/',\n",
        "         '@', '#', '$', '%', '^',\n",
        "         '&', '*', '(', ')', '_', '+'\n",
        "        ];\n",
        "        self.gaps = [1, 2, 3, 4, 5];\n",
        "\n",
        "    def activity_counts(self, df):\n",
        "        tmp_df = \\\n",
        "        df.groupby('id').agg({'activity': list}).reset_index()\n",
        "        ret = list()\n",
        "        for li in tqdm(tmp_df['activity'].values):\n",
        "            items = list(Counter(li).items())\n",
        "            di = dict()\n",
        "            for k in self.activities:\n",
        "                di[k] = 0\n",
        "            for item in items:\n",
        "                k, v = item[0], item[1]\n",
        "                if k in di:\n",
        "                    di[k] = v\n",
        "            ret.append(di)\n",
        "        ret = pd.DataFrame(ret)\n",
        "        cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
        "        ret.columns = cols\n",
        "        return ret\n",
        "\n",
        "    def event_counts(self, df, colname):\n",
        "        tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
        "        ret = list()\n",
        "        for li in tqdm(tmp_df[colname].values):\n",
        "            items = list(Counter(li).items())\n",
        "            di = dict()\n",
        "            for k in self.events:\n",
        "                di[k] = 0\n",
        "            for item in items:\n",
        "                k, v = item[0], item[1]\n",
        "                if k in di:\n",
        "                    di[k] = v\n",
        "            ret.append(di)\n",
        "        ret = pd.DataFrame(ret)\n",
        "        cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
        "        ret.columns = cols\n",
        "        return ret\n",
        "\n",
        "    def text_change_counts(self, df):\n",
        "        tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
        "        ret = list()\n",
        "        for li in tqdm(tmp_df['text_change'].values):\n",
        "            items = list(Counter(li).items())\n",
        "            di = dict()\n",
        "            for k in self.text_changes:\n",
        "                di[k] = 0\n",
        "            for item in items:\n",
        "                k, v = item[0], item[1]\n",
        "                if k in di:\n",
        "                    di[k] = v\n",
        "            ret.append(di)\n",
        "        ret = pd.DataFrame(ret)\n",
        "        cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
        "        ret.columns = cols\n",
        "        return ret\n",
        "\n",
        "    def match_punctuations(self, df):\n",
        "        tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
        "        ret = list()\n",
        "        for li in tqdm(tmp_df['down_event'].values):\n",
        "            cnt = 0\n",
        "            items = list(Counter(li).items())\n",
        "            for item in items:\n",
        "                k, v = item[0], item[1]\n",
        "                if k in self.punctuations:\n",
        "                    cnt += v\n",
        "            ret.append(cnt)\n",
        "        ret = pd.DataFrame({'punct_cnt': ret})\n",
        "        return ret\n",
        "\n",
        "\n",
        "    def get_input_words(self, df):\n",
        "        tmp_df = \\\n",
        "        df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
        "        tmp_df = \\\n",
        "        tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
        "        tmp_df['text_change'] = \\\n",
        "        tmp_df['text_change'].apply(lambda x: ''.join(x))\n",
        "        tmp_df['text_change'] = \\\n",
        "        tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n",
        "        tmp_df['input_word_count'] = \\\n",
        "        tmp_df['text_change'].apply(len)\n",
        "        tmp_df['input_word_length_mean'] = \\\n",
        "        tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
        "        tmp_df['input_word_length_max'] = \\\n",
        "        tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
        "        tmp_df['input_word_length_std'] = \\\n",
        "        tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
        "        tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
        "        return tmp_df;\n",
        "\n",
        "    def make_feats(self, df):\n",
        "\n",
        "        PrintColor(\"\\n---> Starting to engineer features <---\\n\", color = Fore.RED);\n",
        "\n",
        "        # initialize features dataframe\n",
        "        feats = pd.DataFrame({'id': df['id'].unique().tolist()})\n",
        "\n",
        "        # get shifted features\n",
        "        # time shift\n",
        "        PrintColor(\"\\nEngineering time data\\n\")\n",
        "        for gap in self.gaps:\n",
        "            PrintColor(f\"> for gap {gap}\");\n",
        "            df[f'up_time_shift{gap}'] = df.groupby('id')['up_time'].shift(gap);\n",
        "            df[f'action_time_gap{gap}'] = df['down_time'] - df[f'up_time_shift{gap}'];\n",
        "        df.drop(columns=[f'up_time_shift{gap}' for gap in self.gaps], inplace=True);\n",
        "\n",
        "        # cursor position shift\n",
        "        PrintColor(\"\\nEngineering cursor position data\\n\")\n",
        "        for gap in self.gaps:\n",
        "            PrintColor(f\"> for gap {gap}\");\n",
        "            df[f'cursor_position_shift{gap}'] = df.groupby('id')['cursor_position'].shift(gap);\n",
        "            df[f'cursor_position_change{gap}'] = df['cursor_position'] - df[f'cursor_position_shift{gap}'];\n",
        "            df[f'cursor_position_abs_change{gap}'] = np.abs(df[f'cursor_position_change{gap}']);\n",
        "        df.drop(columns=[f'cursor_position_shift{gap}' for gap in self.gaps], inplace=True);\n",
        "\n",
        "        # word count shift\n",
        "        PrintColor(\"\\nEngineering word count data\\n\")\n",
        "        for gap in self.gaps:\n",
        "            PrintColor(f\"> for gap {gap}\");\n",
        "            df[f'word_count_shift{gap}'] = df.groupby('id')['word_count'].shift(gap);\n",
        "            df[f'word_count_change{gap}'] = df['word_count'] - df[f'word_count_shift{gap}'];\n",
        "            df[f'word_count_abs_change{gap}'] = np.abs(df[f'word_count_change{gap}']);\n",
        "        df.drop(columns=[f'word_count_shift{gap}' for gap in self.gaps], inplace=True);\n",
        "\n",
        "        # get aggregate statistical features\n",
        "        PrintColor(\"\\nEngineering statistical summaries for features\\n\");\n",
        "\n",
        "        feats_stat = \\\n",
        "        [\n",
        "            ('event_id', ['max']),\n",
        "            ('up_time', ['max']),\n",
        "            ('action_time', ['max', 'sum', 'std']),\n",
        "            ('activity', ['nunique']),\n",
        "            ('down_event', ['nunique']),\n",
        "            ('up_event', ['nunique']),\n",
        "            ('text_change', ['nunique']),\n",
        "            ('cursor_position', ['nunique', 'max', 'sum']),\n",
        "            ('word_count', ['nunique', 'max', 'mean'])\n",
        "        ];\n",
        "\n",
        "        for gap in self.gaps:\n",
        "            feats_stat.extend([\n",
        "                (f'action_time_gap{gap}', ['max', 'min', 'std', 'sum']),\n",
        "                (f'cursor_position_change{gap}', ['max', 'std', 'sum']),\n",
        "                (f'word_count_change{gap}', ['max','std', 'sum'])\n",
        "            ])\n",
        "\n",
        "        pbar = tqdm(feats_stat);\n",
        "\n",
        "        for item in pbar:\n",
        "            colname, methods = item[0], item[1];\n",
        "\n",
        "            for method in methods:\n",
        "                pbar.set_postfix();\n",
        "                if isinstance(method, str):\n",
        "                    method_name = method;\n",
        "                else:\n",
        "                    method_name = method.__name__;\n",
        "\n",
        "                pbar.set_postfix(column=colname, method=method_name);\n",
        "                tmp_df = \\\n",
        "                df.groupby(['id']).\\\n",
        "                agg({colname: method}).\\\n",
        "                reset_index().\\\n",
        "                rename(columns={colname: f'{colname}_{method_name}'})\n",
        "                feats = feats.merge(tmp_df, on='id', how='left');\n",
        "\n",
        "        # counts\n",
        "        PrintColor(\"\\nEngineering activity counts data\\n\");\n",
        "        tmp_df = self.activity_counts(df);\n",
        "        feats = pd.concat([feats, tmp_df], axis=1);\n",
        "\n",
        "        PrintColor(\"\\nEngineering event counts data\\n\");\n",
        "        tmp_df = self.event_counts(df, 'down_event');\n",
        "        feats  = pd.concat([feats, tmp_df], axis=1);\n",
        "        tmp_df = self.event_counts(df, 'up_event');\n",
        "        feats  = pd.concat([feats, tmp_df], axis=1);\n",
        "\n",
        "        PrintColor(\"\\nEngineering text change counts data\\n\");\n",
        "        tmp_df = self.text_change_counts(df);\n",
        "        feats  = pd.concat([feats, tmp_df], axis=1);\n",
        "\n",
        "        PrintColor(\"\\nEngineering punctuation counts data\\n\");\n",
        "        tmp_df = self.match_punctuations(df);\n",
        "        feats  = pd.concat([feats, tmp_df], axis=1);\n",
        "\n",
        "        # input words\n",
        "        PrintColor(\"\\nEngineering input words data\\n\");\n",
        "        tmp_df = self.get_input_words(df);\n",
        "        feats = pd.merge(feats, tmp_df, on='id', how='left');\n",
        "\n",
        "        # compare feats\n",
        "        PrintColor(\"\\nEngineering ratios data\\n\");\n",
        "        feats['word_time_ratio']  = feats['word_count_max'] / feats['up_time_max'];\n",
        "        feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max'];\n",
        "        feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max'];\n",
        "        feats['idle_time_ratio']  = feats['action_time_gap1_sum'] / feats['up_time_max'];\n",
        "\n",
        "        PrintColor(\"\\nDone!\\n\");\n",
        "        return feats;\n",
        "\n",
        "print();\n",
        "collect();\n",
        "PrintColor(f\"\\n\" + GetMemUsage(), color = Fore.RED);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yDOiOdg57Gr",
        "outputId": "e15b9e9a-0812-40c4-b92c-2da3eab1b574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m\u001b[31m\n",
            "RAM memory GB usage = 0.2847\u001b[0m\n",
            "CPU times: user 196 ms, sys: 813 µs, total: 197 ms\n",
            "Wall time: 234 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOO9jVu18P6v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}